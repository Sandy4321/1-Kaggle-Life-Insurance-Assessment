{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prudential Life Insurance, Kaggle project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Kaggle DataScience Projet\n",
    "Prudential Life Insurance\n",
    "By Yannick SCHINI\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import Imputer, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data and infos about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get the data\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "train_data.set_index('Id', inplace=True)\n",
    "#test_data.set_index('Id', inplace=True)\n",
    "\n",
    "#print(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(np.shape(test_data))\n",
    "print(np.shape(train_data))\n",
    "print(test_data['Response'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = train_data['Response']\n",
    "del train_data['Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get list of categorical inputs\n",
    "categorical_data_list = []\n",
    "categorical_data = \"Product_Info_1, Product_Info_2, Product_Info_3, Product_Info_5, Product_Info_6, Product_Info_7, Employment_Info_2, Employment_Info_3, Employment_Info_5, InsuredInfo_1, InsuredInfo_2, InsuredInfo_3, InsuredInfo_4, InsuredInfo_5, InsuredInfo_6, InsuredInfo_7, Insurance_History_1, Insurance_History_2, Insurance_History_3, Insurance_History_4, Insurance_History_7, Insurance_History_8, Insurance_History_9, Family_Hist_1, Medical_History_2, Medical_History_3, Medical_History_4, Medical_History_5, Medical_History_6, Medical_History_7, Medical_History_8, Medical_History_9, Medical_History_11, Medical_History_12, Medical_History_13, Medical_History_14, Medical_History_16, Medical_History_17, Medical_History_18, Medical_History_19, Medical_History_20, Medical_History_21, Medical_History_22, Medical_History_23, Medical_History_25, Medical_History_26, Medical_History_27, Medical_History_28, Medical_History_29, Medical_History_30, Medical_History_31, Medical_History_33, Medical_History_34, Medical_History_35, Medical_History_36, Medical_History_37, Medical_History_38, Medical_History_39, Medical_History_40, Medical_History_41\"\n",
    "for category in categorical_data.split():\n",
    "    category = category.replace(',','')\n",
    "    categorical_data_list.append(category)\n",
    "#print(categorical_data_list)\n",
    "\n",
    "# Get list of continuous inputs\n",
    "continuous_data_list = []\n",
    "continuous_data = \"Product_Info_4, Ins_Age, Ht, Wt, BMI, Employment_Info_1, Employment_Info_4, Employment_Info_6, Insurance_History_5, Family_Hist_2, Family_Hist_3, Family_Hist_4, Family_Hist_5\"\n",
    "for category in continuous_data.split():\n",
    "    category = category.replace(',','')\n",
    "    continuous_data_list.append(category)\n",
    "#print(continuous_data_list)\n",
    "\n",
    "# Get list of discrete inputs\n",
    "discrete_data_list = []\n",
    "discrete_data = \"Medical_History_1, Medical_History_10, Medical_History_15, Medical_History_24, Medical_History_32\"\n",
    "for category in discrete_data.split():\n",
    "    category = category.replace(',','')\n",
    "    discrete_data_list.append(category)\n",
    "#print(discrete_data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Changing the data type in order to perform one-hot-encoding on all categorical type data fields\n",
    "#for item in categorical_data_list:\n",
    "#    train_data[item] = train_data[item].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(train_data.dtypes)\n",
    "df = pd.get_dummies(train_data)\n",
    "test = pd.get_dummies(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(np.shape(df))\n",
    "#print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(continuous_data_list)\n",
    "for item in continuous_data_list:\n",
    "    df[item] = (df[item] - df[item].mean())/df[item].std()\n",
    "    test[item] = (test[item] - df[item].mean())/df[item].std()\n",
    "    \n",
    "for item in discrete_data_list:\n",
    "    df[item] = (df[item] - df[item].mean())/df[item].std()\n",
    "    test[item] = (test[item] - df[item].mean())/df[item].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imr = Imputer(missing_values='NaN', strategy = 'mean', axis = 0)\n",
    "imf = imr.fit(df)\n",
    "df_imp = imr.transform(df)\n",
    "test_imp = imr.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.516242569172\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(penalty = 'l1', C=0.1)\n",
    "lr.fit(df_imp, y)\n",
    "print('Training accuracy:', lr.score(df_imp, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = lr.predict(test_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_out = pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_out.columns = ['Response']\n",
    "df_out['Id'] = test_data['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Response  Id\n",
      "0         1   1\n",
      "1         8   3\n",
      "2         8   4\n",
      "3         8   9\n",
      "4         8  12\n"
     ]
    }
   ],
   "source": [
    "print(df_out.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_out.to_csv('test_scores.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Get visibility about the data + get dummy features for 'Product_Info_2' which is a string type column\n",
    "\n",
    "print(np.shape(train_data))\n",
    "print(len(categorical_data_list))\n",
    "print(len(discrete_data_list))\n",
    "print(len(continuous_data_list))\n",
    "\n",
    "train_data_2 = pd.get_dummies(train_data)\n",
    "\"\"\"\"Train_data_2 = train_data avec get_dummies utilisée sur la colonne 'Product_Info_2', \n",
    "qui contenait 19 valeurs différents (126 colonnes - la colonne 'Product_Info_2 initiale + les 19 nouvelles = 144 colonnes dans train_data_2)\"\"\"\n",
    "print(np.shape(train_data_2))\n",
    "print(len(np.unique(train_data['Product_Info_2'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "categorical_data_list.remove('Product_Info_2')\n",
    "print(len(categorical_data_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ohe = OneHotEncoder()\n",
    "for item in categorical_data_list:\n",
    "    ohe.fit_transform(train_data[item])\n",
    "    train_data[item]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "categorical_data_df = train_data_2[categorical_data_list]\n",
    "print(np.shape(categorical_data_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ohe = OneHotEncoder()\n",
    "categorical_OHE_data = pd.DataFrame(ohe.fit_transform(train_data_2, train_data_2.loc(categorical_data_list)).toarray())\n",
    "\n",
    "print(np.shape(categorical_data_df))\n",
    "print(np.shape(categorical_OHE_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
